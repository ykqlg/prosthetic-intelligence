{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "import shutil\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = signal.butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = signal.butter(order, cutoff,fs=fs, btype='high', analog=False)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20240104_091258.csv has 2664 rows\n",
      "output/20240104_091511.csv has 2647 rows\n",
      "output/20240104_094232.csv has 2646 rows\n",
      "output/20240104_094302.csv has 2678 rows\n",
      "output/20240104_094325.csv has 2668 rows\n",
      "output/20240104_094355.csv has 2662 rows\n",
      "output/20240104_094428.csv has 2660 rows\n",
      "output/20240104_094500.csv has 2636 rows\n",
      "output/20240104_094524.csv has 2671 rows\n",
      "output/20240104_094552.csv has 2662 rows\n",
      "output/20240104_095025.csv has 2650 rows\n",
      "output/20240104_095103.csv has 2654 rows\n",
      "output/20240104_095131.csv has 2662 rows\n",
      "output/20240104_095247.csv has 2644 rows\n",
      "output/20240104_103510.csv has 2634 rows\n",
      "output/20240104_103726.csv has 2675 rows\n",
      "output/20240104_103910.csv has 2650 rows\n",
      "output/20240104_104247.csv has 2660 rows\n",
      "output/20240104_104319.csv has 2652 rows\n",
      "output/20240104_104408.csv has 2663 rows\n",
      "output/20240104_104623.csv has 2679 rows\n",
      "output/20240104_104652.csv has 2684 rows\n",
      "output/20240104_104717.csv has 2672 rows\n",
      "output/20240104_104832.csv has 2680 rows\n",
      "output/20240104_104902.csv has 2646 rows\n",
      "output/20240104_104948.csv has 2658 rows\n",
      "output/20240104_105015.csv has 2663 rows\n",
      "output/20240104_105044.csv has 2656 rows\n",
      "output/20240104_105108.csv has 2666 rows\n",
      "output/20240104_105200.csv has 2643 rows\n",
      "output/20240104_105315.csv has 2651 rows\n",
      "output/20240104_151321.csv has 2658 rows\n",
      "output/20240104_151343.csv has 2656 rows\n",
      "output/20240104_151441.csv has 2640 rows\n",
      "output/20240104_151512.csv has 2660 rows\n",
      "output/20240104_151537.csv has 2660 rows\n",
      "output/20240104_151907.csv has 2684 rows\n",
      "output/20240104_151942.csv has 2687 rows\n",
      "output/20240109_153020.csv has 2660 rows\n",
      "output/20240109_153131.csv has 2655 rows\n",
      "output/20240109_153202.csv has 2651 rows\n",
      "output/20240109_153232.csv has 2664 rows\n"
     ]
    }
   ],
   "source": [
    "# 数据清洗：数据滤波，裁剪，绘制\n",
    "def plot_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    ACC_X = df['ACC_X']\n",
    "    ACC_Y = df['ACC_Y']\n",
    "    ACC_Z = df['ACC_Z']\n",
    "    time = df['Time']\n",
    "\n",
    "    # 滤波参数\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "    # plt.specgram(ACC_Z, NFFT=1024, Fs=fs, detrend=None)\n",
    "    cutoff_L,cutoff_H = 500,20\n",
    "    order_L,order_H = 6,5\n",
    "    truncate_length = 0\n",
    "    \n",
    "    ACC_X_filtered_L = butter_lowpass_filter(ACC_X, cutoff_L, fs, order_L)\n",
    "    ACC_X_filtered_H = butter_highpass_filter(ACC_X_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    ACC_Y_filtered_L = butter_lowpass_filter(ACC_Y, cutoff_L, fs, order_L)\n",
    "    ACC_Y_filtered_H = butter_highpass_filter(ACC_Y_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    ACC_Z_filtered_L = butter_lowpass_filter(ACC_Z, cutoff_L, fs, order_L)\n",
    "    ACC_Z_filtered_H = butter_highpass_filter(ACC_Z_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    time = time.values[truncate_length:]\n",
    "\n",
    "    # 截取窗口\n",
    "    threshold = 1000 \n",
    "    peaks, _ = find_peaks(ACC_Z_filtered_H, height=threshold)\n",
    "    pivot = peaks[0]\n",
    "    start_index = pivot - int(0.4*fs)\n",
    "    end_index = pivot + int(1.4*fs)\n",
    "    # print(\"index:\",start_index,end_index)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    \n",
    "    axes[0].plot(time,ACC_X_filtered_H, label='ACC_X Data')\n",
    "    axes[1].plot(time,ACC_Y_filtered_H, label='ACC_Y Data')\n",
    "    axes[2].plot(time,ACC_Z_filtered_H, label='ACC_Z Data')\n",
    "    \n",
    "    for i, data_name in enumerate(['ACC_X', 'ACC_Y', 'ACC_Z']): \n",
    "        \n",
    "        axes[i].axvspan(time[start_index], time[end_index], facecolor='red', alpha=0.2, label='Target Waveform')\n",
    "        \n",
    "        # ax.set_title(data_name)\n",
    "        axes[i].set_xlabel(\"Time (s)\")\n",
    "        axes[i].set_ylabel(data_name+' (mg)')\n",
    "        axes[i].legend()\n",
    "    plt.suptitle(filename)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return start_index,end_index\n",
    " \n",
    "    \n",
    "def crop_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    ACC = df['ACC_Z']\n",
    "    time = df['Time']\n",
    "\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "    truncate_length = 0\n",
    "    \n",
    "\n",
    "    ACC_filtered_L = butter_lowpass_filter(ACC, cutoff=500, fs=fs, order=6)\n",
    "    ACC_filtered_H = butter_highpass_filter(ACC_filtered_L, cutoff=20, fs=fs, order=5)[truncate_length:]\n",
    "    time = time.values[truncate_length:]\n",
    "    \n",
    "    threshold = 1000 \n",
    "    peaks, _ = find_peaks(ACC_filtered_H, height=threshold)\n",
    "    pivot = peaks[0]\n",
    "    start_index = pivot - int(0.5*fs)\n",
    "    end_index = pivot + int(1.5*fs)\n",
    "    \n",
    "    df_cropped = df[start_index:end_index + 1]\n",
    "    df_cropped.to_csv(filename, index=False)\n",
    "    \n",
    "def clean_data(labelfile):\n",
    "    \n",
    "    source_folder = 'output'  # 替换为你的源文件夹路径\n",
    "    backup_folder = 'output_backup'  # 替换为你的备份文件夹路径\n",
    "\n",
    "    shutil.copytree(source_folder, backup_folder)\n",
    "    \n",
    "    df = pd.read_csv(labelfile)\n",
    "    for index, row in df.iterrows():\n",
    "        filepath = row.iloc[0]\n",
    "        # plot_data(filepath)\n",
    "        # crop_data(filepath)\n",
    "\n",
    "        # 检查裁剪后的文件的行数，避免出现错误数据\n",
    "        with open(filepath, 'r') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "            row_count = len(list(csv_reader))\n",
    "            print(f\"{filepath} has {row_count} rows\")\n",
    "    \n",
    "        \n",
    "# clean_data('./label_file.csv')\n",
    "\n",
    "# plot_all_data('./output/20240104_094355.csv')\n",
    "\n",
    "# crop_data('./test/20240104_091258.csv')\n",
    "# plot_data('./output_backup/20240104_104247.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_elements: ['FilePath', 'output/20240104_091258.csv', 'output/20240104_091511.csv', 'output/20240104_094232.csv', 'output/20240104_094302.csv', 'output/20240104_094325.csv', 'output/20240104_094355.csv', 'output/20240104_094428.csv', 'output/20240104_094500.csv', 'output/20240104_094524.csv', 'output/20240104_094552.csv', 'output/20240104_095025.csv', 'output/20240104_095103.csv', 'output/20240104_095131.csv', 'output/20240104_095247.csv', 'output/20240104_103510.csv', 'output/20240104_103726.csv', 'output/20240104_103910.csv', 'output/20240104_104247.csv', 'output/20240104_104319.csv', 'output/20240104_104408.csv', 'output/20240104_104623.csv', 'output/20240104_104652.csv', 'output/20240104_104717.csv', 'output/20240104_104832.csv', 'output/20240104_104902.csv', 'output/20240104_104948.csv', 'output/20240104_105015.csv', 'output/20240104_105044.csv', 'output/20240104_105108.csv', 'output/20240104_105200.csv', 'output/20240104_105315.csv', 'output/20240104_151321.csv', 'output/20240104_151343.csv', 'output/20240104_151441.csv', 'output/20240104_151512.csv', 'output/20240104_151537.csv', 'output/20240104_151907.csv', 'output/20240104_151942.csv', 'output/20240109_153020.csv', 'output/20240109_153131.csv', 'output/20240109_153202.csv', 'output/20240109_153232.csv']\n",
      "folder_files: ['20240104_091511.csv', '20240104_105200.csv', '20240104_104247.csv', '20240104_104948.csv', '20240104_104717.csv', '20240104_104623.csv', '20240104_104832.csv', '20240104_094552.csv', '20240104_094500.csv', '20240104_095025.csv', '20240104_095247.csv', '20240104_095131.csv', '20240104_091258.csv', '20240104_103510.csv', '20240104_104319.csv', '20240104_151321.csv', '20240104_105044.csv', '20240109_153202.csv', '20240104_095103.csv', '20240104_103910.csv', '20240104_152009.csv', '20240109_153232.csv', '20240104_104408.csv', '20240104_103726.csv', '20240104_094232.csv', '20240104_151441.csv', '20240104_105315.csv', '20240109_153131.csv', '20240109_153020.csv', '20240104_105138.csv', '20240109_153254.csv', '20240104_151942.csv', '20240104_094428.csv', '20240104_094325.csv', '20240104_151343.csv', '20240104_094302.csv', '20240104_151537.csv', '20240104_105108.csv', '20240104_105015.csv', '20240104_094524.csv', '20240104_151907.csv', '20240109_153101.csv', '20240109_152936.csv', '20240104_151512.csv', '20240104_094355.csv', '20240104_104652.csv', '20240104_104902.csv']\n",
      "count: 5\n"
     ]
    }
   ],
   "source": [
    "# 根据标签文件的内容，清除./output文件夹中的无关文件\n",
    "def remove_files_not_in_label(tag_file, folder_path):\n",
    "    # 读取标签文件的第一列元素\n",
    "    with open(tag_file, 'r') as tag_csv:\n",
    "        tag_reader = csv.reader(tag_csv)\n",
    "        # 跳过第一行（列名称）\n",
    "        next(tag_reader)\n",
    "        tag_elements = [row[0] for row in tag_reader]\n",
    "\n",
    "    # 获取文件夹中的所有文件名\n",
    "    folder_files = os.listdir(folder_path)\n",
    "    print('tag_elements:',tag_elements)\n",
    "    print('folder_files:',folder_files)\n",
    "\n",
    "    count = 0\n",
    "    # 遍历文件夹中的文件名\n",
    "    for filename in folder_files:\n",
    "        # 检查文件名是否在标签文件的第一列元素中\n",
    "        if not any(filename in tag for tag in tag_elements):\n",
    "            # 构造文件的完整路径\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "            # print(f\"File '{file_path}' removed.\")\n",
    "            count += 1\n",
    "    \n",
    "    print('count:',count)\n",
    "\n",
    "tag_file_path = './label_file.csv'\n",
    "folder_path = './output/'\n",
    "remove_files_not_in_label(tag_file_path, folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
