{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "import shutil\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = signal.butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = signal.butter(order, cutoff,fs=fs, btype='high', analog=False)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_elements: ['output/20240104_091258.csv', 'output/20240104_091511.csv', 'output/20240104_094232.csv', 'output/20240104_094302.csv', 'output/20240104_094325.csv', 'output/20240104_094355.csv', 'output/20240104_094428.csv', 'output/20240104_094500.csv', 'output/20240104_094524.csv', 'output/20240104_094552.csv', 'output/20240104_095025.csv', 'output/20240104_095103.csv', 'output/20240104_095131.csv', 'output/20240104_095247.csv', 'output/20240104_103510.csv', 'output/20240104_103726.csv', 'output/20240104_103910.csv', 'output/20240104_104247.csv', 'output/20240104_104319.csv', 'output/20240104_104408.csv', 'output/20240104_104623.csv', 'output/20240104_104652.csv', 'output/20240104_104717.csv', 'output/20240104_104832.csv', 'output/20240104_104902.csv', 'output/20240104_104948.csv', 'output/20240104_105015.csv', 'output/20240104_105044.csv', 'output/20240104_105108.csv', 'output/20240104_105200.csv', 'output/20240104_105315.csv', 'output/20240104_151321.csv', 'output/20240104_151343.csv', 'output/20240104_151441.csv', 'output/20240104_151512.csv', 'output/20240104_151537.csv', 'output/20240104_151907.csv', 'output/20240104_151942.csv', 'output/20240109_153020.csv', 'output/20240109_153131.csv', 'output/20240109_153202.csv', 'output/20240109_153232.csv']\n",
      "folder_files: ['20240104_091406.csv', '20240104_091431.csv', '20240104_091511.csv', '20240104_105200.csv', '20240104_105241.csv', '20240102_155151.csv', '20240104_151652.csv', '20240104_151422.csv', '20240104_103658.csv', '20240104_104247.csv', '20240104_103425.csv', '20240104_104948.csv', '20240104_105506.csv', '20240104_104717.csv', '20240104_104623.csv', '20240104_104832.csv', '20240104_104029.csv', '20240104_085801.csv', '20240104_094552.csv', '20240104_090048.csv', '20240104_094500.csv', '20240104_093330.csv', '20240102_155516.csv', '20240104_095025.csv', '20240104_091647.csv', '20240103_095224.csv', '20240104_095310.csv', '20240104_095247.csv', '20240104_095131.csv', '20240104_091258.csv', '20240103_095726.csv', '20240104_103510.csv', '20240104_104435.csv', '20240104_150954.csv', '20240104_091626.csv', '20240104_104319.csv', '20240104_103751.csv', '20240104_151321.csv', '20240104_151055.csv', '20240104_105044.csv', '20240104_095103.csv', '20240104_151138.csv', '20240104_104800.csv', '20240104_094813.csv', '20240104_103910.csv', '20240104_152009.csv', '20240104_104408.csv', '20240104_094640.csv', '20240104_103726.csv', '20240104_094232.csv', '20240102_205540.csv', '20240104_104928.csv', '20240104_151441.csv', '20240104_151844.csv', '20240104_151601.csv', '20240103_095113.csv', '20240104_091549.csv', '20240104_105315.csv', '20240102_210711.csv', '20240104_090155.csv', '20240102_205751.csv', '20240104_090314.csv', '20240102_154940.csv', '20240104_095207.csv', '20240104_093357.csv', '20240104_104345.csv', '20240104_151226.csv', '20240104_103316.csv', '20240102_202653.csv', '20240104_105357.csv', '20240104_103946.csv', '20240104_090846.csv', '20240104_105138.csv', '20240104_151032.csv', '20240104_090235.csv', '20240104_151408.csv', '20240104_104502.csv', '20240104_151942.csv', '20240104_094428.csv', '20240104_094030.csv', '20240104_094325.csv', '20240102_155111.csv', '20240104_151343.csv', '20240104_094302.csv', '20240104_151537.csv', '20240104_105108.csv', '20240104_105336.csv', '20240104_105015.csv', '20240104_094524.csv', '20240104_090755.csv', '20240104_091451.csv', '20240104_105440.csv', '20240104_151907.csv', '20240102_202810.csv', '20240104_151625.csv', '20240104_094935.csv', '20240104_103544.csv', '20240104_104215.csv', '20240104_090026.csv', '20240104_094745.csv', '20240104_104557.csv', '20240104_094615.csv', '20240104_104533.csv', '20240104_091120.csv', '20240104_151512.csv', '20240104_094355.csv', '20240104_090341.csv', '20240104_090000.csv', '20240104_104652.csv', '20240104_104902.csv']\n",
      "count: 72\n"
     ]
    }
   ],
   "source": [
    "# 根据标签文件的内容，清除./output文件夹中的无关文件\n",
    "def remove_files_not_in_label(tag_file, folder_path):\n",
    "    # 读取标签文件的第一列元素\n",
    "    with open(tag_file, 'r') as tag_csv:\n",
    "        tag_reader = csv.reader(tag_csv)\n",
    "        # 跳过第一行（列名称）\n",
    "        next(tag_reader)\n",
    "        tag_elements = [row[0] for row in tag_reader]\n",
    "\n",
    "    # 获取文件夹中的所有文件名\n",
    "    folder_files = os.listdir(folder_path)\n",
    "    print('tag_elements:',tag_elements)\n",
    "    print('folder_files:',folder_files)\n",
    "\n",
    "    count = 0\n",
    "    # 遍历文件夹中的文件名\n",
    "    for filename in folder_files:\n",
    "        # 检查文件名是否在标签文件的第一列元素中\n",
    "        if not any(filename in tag for tag in tag_elements):\n",
    "            # 构造文件的完整路径\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "            # print(f\"File '{file_path}' removed.\")\n",
    "            count += 1\n",
    "    \n",
    "    print('count:',count)\n",
    "\n",
    "tag_file_path = './label_file.csv'\n",
    "folder_path = './output/'\n",
    "remove_files_not_in_label(tag_file_path, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([41, 60]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看当前采集数据的标签分布情况\n",
    "\n",
    "df = pd.read_csv('./label_file.csv')\n",
    "labels = df['Label']\n",
    "np.unique(labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_cropped/20240104_091258.csv has 2664 rows\n",
      "./output_cropped/20240104_091511.csv has 2647 rows\n",
      "./output_cropped/20240104_094232.csv has 2646 rows\n",
      "./output_cropped/20240104_094302.csv has 2678 rows\n",
      "./output_cropped/20240104_094325.csv has 2668 rows\n",
      "./output_cropped/20240104_094355.csv has 2662 rows\n",
      "./output_cropped/20240104_094428.csv has 2660 rows\n",
      "./output_cropped/20240104_094500.csv has 2636 rows\n",
      "./output_cropped/20240104_094524.csv has 2671 rows\n",
      "./output_cropped/20240104_094552.csv has 2662 rows\n",
      "./output_cropped/20240104_095025.csv has 2650 rows\n",
      "./output_cropped/20240104_095103.csv has 2654 rows\n",
      "./output_cropped/20240104_095131.csv has 2662 rows\n",
      "./output_cropped/20240104_095247.csv has 2644 rows\n",
      "./output_cropped/20240104_103510.csv has 2634 rows\n",
      "./output_cropped/20240104_103726.csv has 2675 rows\n",
      "./output_cropped/20240104_103910.csv has 2650 rows\n",
      "./output_cropped/20240104_104247.csv has 2660 rows\n",
      "./output_cropped/20240104_104319.csv has 2652 rows\n",
      "./output_cropped/20240104_104408.csv has 2663 rows\n",
      "./output_cropped/20240104_104623.csv has 2679 rows\n",
      "./output_cropped/20240104_104652.csv has 2684 rows\n",
      "./output_cropped/20240104_104717.csv has 2672 rows\n",
      "./output_cropped/20240104_104832.csv has 2680 rows\n",
      "./output_cropped/20240104_104902.csv has 2646 rows\n",
      "./output_cropped/20240104_104948.csv has 2658 rows\n",
      "./output_cropped/20240104_105015.csv has 2663 rows\n",
      "./output_cropped/20240104_105044.csv has 2656 rows\n",
      "./output_cropped/20240104_105108.csv has 2666 rows\n",
      "./output_cropped/20240104_105200.csv has 2643 rows\n",
      "./output_cropped/20240104_105315.csv has 2651 rows\n",
      "./output_cropped/20240104_151321.csv has 2658 rows\n",
      "./output_cropped/20240104_151343.csv has 2656 rows\n",
      "./output_cropped/20240104_151441.csv has 2640 rows\n",
      "./output_cropped/20240104_151512.csv has 2660 rows\n",
      "./output_cropped/20240104_151537.csv has 2660 rows\n",
      "./output_cropped/20240104_151907.csv has 2684 rows\n",
      "./output_cropped/20240104_151942.csv has 2687 rows\n"
     ]
    }
   ],
   "source": [
    "# 数据清洗部分\n",
    "\n",
    "# 滤波绘制\n",
    "def plot_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    ACC_X = df['ACC_X']\n",
    "    ACC_Y = df['ACC_Y']\n",
    "    ACC_Z = df['ACC_Z']\n",
    "    time = df['Time']\n",
    "\n",
    "    # 滤波参数\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "    # plt.specgram(ACC_Z, NFFT=1024, Fs=fs, detrend=None)\n",
    "    cutoff_L,cutoff_H = 500,20\n",
    "    order_L,order_H = 6,5\n",
    "    truncate_length = 0\n",
    "    \n",
    "    ACC_X_filtered_L = butter_lowpass_filter(ACC_X, cutoff_L, fs, order_L)\n",
    "    ACC_X_filtered_H = butter_highpass_filter(ACC_X_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    ACC_Y_filtered_L = butter_lowpass_filter(ACC_Y, cutoff_L, fs, order_L)\n",
    "    ACC_Y_filtered_H = butter_highpass_filter(ACC_Y_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    ACC_Z_filtered_L = butter_lowpass_filter(ACC_Z, cutoff_L, fs, order_L)\n",
    "    ACC_Z_filtered_H = butter_highpass_filter(ACC_Z_filtered_L, cutoff_H, fs, order_H)[truncate_length:]\n",
    "    time = time.values[truncate_length:]\n",
    "\n",
    "    # 截取窗口\n",
    "    threshold = 1000 \n",
    "    peaks, _ = find_peaks(ACC_Z_filtered_H, height=threshold)\n",
    "    pivot = peaks[0]\n",
    "    start_index = pivot - int(0.4*fs)\n",
    "    end_index = pivot + int(1.4*fs)\n",
    "    # print(\"index:\",start_index,end_index)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    \n",
    "    axes[0].plot(time,ACC_X_filtered_H, label='ACC_X Data')\n",
    "    axes[1].plot(time,ACC_Y_filtered_H, label='ACC_Y Data')\n",
    "    axes[2].plot(time,ACC_Z_filtered_H, label='ACC_Z Data')\n",
    "    \n",
    "    for i, data_name in enumerate(['ACC_X', 'ACC_Y', 'ACC_Z']): \n",
    "        \n",
    "        axes[i].axvspan(time[start_index], time[end_index], facecolor='red', alpha=0.2, label='Target Waveform')\n",
    "        \n",
    "        # ax.set_title(data_name)\n",
    "        # axes[i].set_xlabel(\"Time (s)\")\n",
    "        axes[i].set_ylabel(data_name+' (mg)')\n",
    "        # axes[i].legend()\n",
    "    axes[0].set_xticks([])\n",
    "    axes[1].set_xticks([])\n",
    "    axes[2].set_xlabel(\"Time (s)\")\n",
    "        \n",
    "    plt.suptitle(filename)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return start_index,end_index\n",
    "\n",
    "# 裁剪目标波形\n",
    "def crop_data(filepath, newfoldername):\n",
    "    \n",
    "    newfilepath = os.path.join('.', newfoldername, os.path.basename(filepath))\n",
    "    # print(filepath)\n",
    "    # print(newfilepath)\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    ACC = df['ACC_Z']\n",
    "    time = df['Time']\n",
    "\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "    truncate_length = 0\n",
    "    \n",
    "\n",
    "    ACC_filtered_L = butter_lowpass_filter(ACC, cutoff=500, fs=fs, order=6)\n",
    "    ACC_filtered_H = butter_highpass_filter(ACC_filtered_L, cutoff=20, fs=fs, order=5)[truncate_length:]\n",
    "    time = time.values[truncate_length:]\n",
    "    \n",
    "    threshold = 1000 \n",
    "    peaks, _ = find_peaks(ACC_filtered_H, height=threshold)\n",
    "    pivot = peaks[0]\n",
    "    start_index = pivot - int(0.5*fs)\n",
    "    end_index = pivot + int(1.5*fs)\n",
    "    \n",
    "    df_cropped = df[start_index:end_index + 1]\n",
    "    df_cropped.to_csv(newfilepath, index=False)\n",
    "    return newfilepath\n",
    "   \n",
    "# 根据标签文件，裁剪目标波形\n",
    "def clean_data(labelfile, target_folder):\n",
    "    \n",
    "    df = pd.read_csv(labelfile)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        filepath = row.iloc[0]\n",
    "        # plot_data(filepath)\n",
    "        new_file_path = crop_data(filepath, target_folder)\n",
    "\n",
    "        # 检查裁剪后的文件的行数，避免出现错误数据\n",
    "        with open(new_file_path, 'r') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "            row_count = len(list(csv_reader))\n",
    "            print(f\"{new_file_path} has {row_count} rows\")\n",
    "            \n",
    "    df['FilePath'] = df['FilePath'].apply(lambda x: x.replace('output', target_folder))\n",
    "    new_label_file_path = './label_file_replaced.csv'\n",
    "    df.to_csv(new_label_file_path, index=False)\n",
    "\n",
    "newfoldername = 'output_cropped'\n",
    "clean_data('./label_file.csv',newfoldername)\n",
    "\n",
    "# crop_data('./output/20240104_091258.csv', newfoldername)\n",
    "\n",
    "# plot_data('./output/20240104_091258.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
