{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import get_window\n",
    "import scipy.fftpack as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emphasized_audio(audio, alpha=0.97):\n",
    "    emphasized_audio = np.append(audio[0], audio[1:] - alpha * audio[:-1])\n",
    "    return emphasized_audio\n",
    "\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "\n",
    "def frame_audio(audio, FFT_size=2048, hop_size=10, sample_rate=44100):\n",
    "    # hop_size in ms\n",
    "    audio = np.pad(audio, int(FFT_size / 2), mode='reflect')\n",
    "    frame_len = np.round(sample_rate * hop_size / 1000).astype(int)\n",
    "    frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "    frames = np.zeros((frame_num, FFT_size))\n",
    "\n",
    "    for n in range(frame_num):\n",
    "        frames[n] = audio[n*frame_len:n*frame_len+FFT_size]\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def freq_to_mel(freq):\n",
    "    return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
    "\n",
    "\n",
    "def met_to_freq(mels):\n",
    "    return 700.0 * (10.0**(mels / 2595.0) - 1.0)\n",
    "\n",
    "\n",
    "def get_filter_points(fmin, fmax, mel_filter_num, FFT_size, sample_rate=44100):\n",
    "    fmin_mel = freq_to_mel(fmin)\n",
    "    fmax_mel = freq_to_mel(fmax)\n",
    "\n",
    "    # print(\"MEL min: {0}\".format(fmin_mel))\n",
    "    # print(\"MEL max: {0}\".format(fmax_mel))\n",
    "\n",
    "    mels = np.linspace(fmin_mel, fmax_mel, num=mel_filter_num+2)\n",
    "    freqs = met_to_freq(mels)\n",
    "    # f(m-1)和f(m)、f(m+1)分别对应第m个滤波器的起始点、中间点和结束点。大家一定要注意的一点是，这里的f(m)对应的值不是频率值，而是对应的sample的索引！比如，我们这里最大频率是22050 Hz, 所以22050Hz对应的是第513个sample，即频率f所对应的值是f/fs*NFFT\n",
    "    return np.floor((FFT_size + 0.5) / sample_rate * freqs).astype(int), freqs\n",
    "\n",
    "\n",
    "def get_filters(filter_points, FFT_size):\n",
    "    filters = np.zeros((len(filter_points)-2, int(FFT_size/2+1)))\n",
    "\n",
    "    for n in range(len(filter_points)-2):\n",
    "        # 相比于原kaggle代码，增加了`endpoint=False`参数\n",
    "        filters[n, filter_points[n]: filter_points[n + 1]] = np.linspace(\n",
    "            0, 1, filter_points[n + 1] - filter_points[n], endpoint=False)\n",
    "        filters[n, filter_points[n + 1]: filter_points[n + 2]] = np.linspace(\n",
    "            1, 0, filter_points[n + 2] - filter_points[n + 1], endpoint=False)\n",
    "\n",
    "    return filters\n",
    "\n",
    "\n",
    "def dct(dct_filter_num, filter_len):\n",
    "    basis = np.empty((dct_filter_num, filter_len))\n",
    "    basis[0, :] = 1.0 / np.sqrt(filter_len)\n",
    "\n",
    "    samples = np.arange(1, 2 * filter_len, 2) * np.pi / (2.0 * filter_len)\n",
    "\n",
    "    for i in range(1, dct_filter_num):\n",
    "        basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / filter_len)\n",
    "\n",
    "    return basis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cepstral_coefficents(filePath, mel_filter_num=10):\n",
    "    df = pd.read_csv(filePath)\n",
    "    y = df['ACC_X'].to_numpy()\n",
    "    t = df['Time'].to_numpy()\n",
    "    sample_rate = int(1/np.mean(np.diff(t)))\n",
    "\n",
    "    # nomalize和emphazie 区别？\n",
    "    # audio = normalize_audio(y)\n",
    "    audio = emphasized_audio(y, alpha=0.97)\n",
    "\n",
    "    hop_size = 15  # ms 以这个作为帧的间隔，相当于stride\n",
    "    FFT_size = 2048\n",
    "\n",
    "    audio_framed = frame_audio(\n",
    "        audio, FFT_size=FFT_size, hop_size=hop_size, sample_rate=sample_rate)\n",
    "\n",
    "    # 加窗 跟hamming？\n",
    "    window = get_window(\"hann\", FFT_size, fftbins=True)\n",
    "    audio_win = audio_framed * window\n",
    "\n",
    "    # 进行STFT\n",
    "    # 这种转置再转置的原因：在音频信号处理中，更习惯将时间窗口放在第一维\n",
    "    audio_winT = np.transpose(audio_win)  # audio_winT.shape:(2048,133)\n",
    "\n",
    "    audio_fft = np.empty(\n",
    "        (int(1 + FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F')\n",
    "\n",
    "    # 对每一帧进行fft\n",
    "    for n in range(audio_fft.shape[1]):\n",
    "        audio_fft[:, n] = fft.fft(audio_winT[:, n], axis=0)[\n",
    "            :audio_fft.shape[0]]\n",
    "\n",
    "    audio_fft = np.transpose(audio_fft)  # audio_fft.shape:(133, 1025)\n",
    "\n",
    "    audio_power = np.square(np.abs(audio_fft))\n",
    "\n",
    "    freq_min = 0\n",
    "    freq_high = sample_rate / 2  # 奈奎斯特频率\n",
    "    # mel_filter_num = 18  # 参数可调\n",
    "\n",
    "    filter_points, mel_freqs = get_filter_points(\n",
    "        freq_min, freq_high, mel_filter_num, FFT_size, sample_rate=44100)\n",
    "\n",
    "    filters = get_filters(filter_points, FFT_size)\n",
    "\n",
    "    enorm = 2.0 / (mel_freqs[2:mel_filter_num+2] - mel_freqs[:mel_filter_num])\n",
    "    filters *= enorm[:, np.newaxis]  # np.newaxis用于增加一个维度，可以与filter的向量元素做内积\n",
    "\n",
    "    audio_filtered = np.dot(filters, np.transpose(audio_power))\n",
    "    # audio_log = 10.0 * np.log10(audio_filtered)  \n",
    "    audio_log = np.log10(audio_filtered) \n",
    "\n",
    "    dct_filter_num = 13\n",
    "    dct_filters = dct(dct_filter_num, mel_filter_num)\n",
    "    cepstral_coefficents = np.dot(dct_filters, audio_log)\n",
    "    # print('logfbank:',cepstral_coefficents)\n",
    "    return cepstral_coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.58032071e+00  6.66232243e+00  6.31704703e+00 ...  5.22991284e+00\n",
      "   6.93591647e+00  4.53956245e+00]\n",
      " [-5.82656650e+00 -7.44399746e+00 -4.07573693e+00 ...  3.30332026e-01\n",
      "  -4.31003598e+00  5.42789232e-01]\n",
      " [ 1.54607152e+00 -9.33230512e-01  2.84592955e+00 ... -1.57403305e+00\n",
      "   1.53067890e+00  5.29194560e+00]\n",
      " ...\n",
      " [-6.76872946e-01  9.91061584e-01 -5.95738854e-01 ... -2.53866724e-01\n",
      "   5.74545388e-01  8.51127529e-01]\n",
      " [ 9.21291867e-01  1.55775906e-01  1.39793521e-03 ... -4.94758185e-01\n",
      "  -1.37871457e-02 -1.64686787e-01]\n",
      " [-1.36767729e-01  3.87471649e-01  5.18921891e-01 ... -2.67114889e-01\n",
      "  -3.89496869e-01  3.56080496e-02]]\n"
     ]
    }
   ],
   "source": [
    "filePath = './output_cropped/20240112_142401.csv'\n",
    "df = pd.read_csv(filePath)\n",
    "sig = df['ACC_X'].to_numpy()\n",
    "t = df['Time'].to_numpy()\n",
    "rate = int(1/np.mean(np.diff(t)))\n",
    "# (rate,sig) = wav.read(\"english.wav\")\n",
    "mfcc_feat = mfcc(sig,rate,winstep=0.015,numcep=13,nfilt=26,nfft=2048,ceplifter=0,winfunc=np.hanning)\n",
    "mfcc_feat_T = np.transpose(mfcc_feat)\n",
    "print(mfcc_feat_T)\n",
    "# d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "# print('library:',fbank_feat[1:3,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85467115e+01,  1.87459661e+01,  1.88940370e+01, ...,\n",
       "         9.82854643e+00,  9.76027664e+00,  9.63635349e+00],\n",
       "       [-1.25994003e+00, -1.32719134e+00, -1.34608307e+00, ...,\n",
       "         3.28889551e+00,  3.32316200e+00,  3.37853059e+00],\n",
       "       [ 5.17202689e-01,  3.13400796e-01,  2.17153549e-01, ...,\n",
       "         1.19968036e+00,  1.27433625e+00,  1.41530998e+00],\n",
       "       ...,\n",
       "       [-1.03467313e+00, -7.77294359e-01, -6.28959963e-01, ...,\n",
       "        -5.53570309e-01, -6.66319563e-01, -8.50148101e-01],\n",
       "       [-5.69074181e-01, -6.17414943e-01, -6.48430215e-01, ...,\n",
       "        -4.29274830e-02, -1.64234390e-02,  2.06089533e-02],\n",
       "       [ 3.67318523e-01,  1.40230935e-01,  1.52986089e-02, ...,\n",
       "         9.37923350e-01,  1.02157892e+00,  1.17514513e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_cepstral_coefficents(filePath,mel_filter_num=26)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
